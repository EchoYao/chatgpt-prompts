# 策略：给予模型“思考”的时间

## 技巧：在模型急于得出结论之前，指导模型自己寻找解决方案

有时，在明确指导模型根据基本原理进行推理之前，我们可能会得到更好的结果。假设我们希望模型评估一个学生对数学问题的解答。最直观的方式是直接询问模型学生的解答是否正确。

|  |  |
| --- | --- |
| **系统** | 判断学生的解答是否正确。 |
| **用户** | 问题概述：我正在搭建一个太阳能发电项目，需要协助计算财务相关的事项。<br>- 土地的价格是每平方英尺 100 美元<br>- 我可以以每平方英尺 250 美元的价格购买太阳能板<br>- 我已经签订了一份保养合同，按照这份合同，我需要支付每年固定的 10 万美元以及每平方英尺额外的 10 美元的费用。<br>那么，第一年的运营总成本是多少呢？这个成本应该以安装面积（平方英尺数）为变量来计算。<br><br>学生的解答：假设安装面积为 x 平方英尺。<br>1. 土地成本为 100x<br>2. 太阳能板成本为 250x<br>3. 维护成本为 100,000 + 10x<br>总成本为 100x（土地）+ 250x（太阳能板）+ 100,000（固定维护费）+ 10x（额外维护费）= 360x + 100,000 |
| **助手** | 学生的解答正确。 |

[在 Playground 中查看详情](https://platform.openai.com/playground/p/default-rushing-to-a-conclusion)

然而，学生的解答其实并不正确！我们可以通过引导模型首先产生它自己的解答，从而让它成功地发现这个问题。

|  |  |
| --- | --- |
| **系统** | 首先，你需要自行找出问题的解答，然后把你的解答与学生的解答进行比较，评定学生的解答是否准确。在你没有自行解决这个问题之前，请不要对学生的解答进行判断。 |
| **用户** | 问题概述：我正在搭建一个太阳能发电项目，需要协助计算财务相关的事项。<br>- 土地的价格是每平方英尺 100 美元<br>- 我可以以每平方英尺 250 美元的价格购买太阳能板<br>- 我已经签订了一份保养合同，按照这份合同，我需要支付每年固定的 10 万美元以及每平方英尺额外的 10 美元的费用。<br>那么，第一年的运营总成本是多少呢？这个成本应该以安装面积（平方英尺数）为变量来计算。<br><br>学生的解答：假设安装面积为 x 平方英尺。<br>1. 土地成本为 100x<br>2. 太阳能板成本为 250x<br>3. 维护成本为 100,000 + 10x<br>总成本为 100x（土地）+ 250x（太阳能板）+ 100,000（固定维护费）+ 10x（额外维护费）= 360x + 100,000 |
| **助手** | 让我们设定 x 为太阳能发电装置的面积，单位为平方英尺。<br>1. 土地成本：100x<br>2. 太阳能板成本：250x<br>3. 维护成本：100,000 + 10x<br>总成本：100x + 250x + 100,000 + 10x = 360x + 100,000<br><br>学生的解答存在错误。他们在计算维护成本时，错误地以 100x 替代了正确的 10x。第一年运行的正确总成本就是 360x + 100,000 美元。 |

[在 Playground 中查看详情](https://platform.openai.com/playground/p/default-avoid-rushing-to-a-conclusion)

## 技巧：运用内心独白或连续提问来隐藏模型的推理过程

先前的策略证明，在回答特定问题之前，模型有时需要深入地推理问题的过程。然而，在某些应用环境中，模型为得出最终答案的推理过程不宜与用户分享。比如，在教导应用里，我们或许希望鼓励学生自行思考答案，但模型对于学生解答的推理过程可能会无意间透露出答案。

内心独白就是能有效应对这种情况的策略。内心独白的主要概念是指导模型将那些需要被用户隐藏的输出部分以一种结构化的形式表现，从而容易进行解析。然后在将输出结果展示给用户之前，将其进行解析处理，最后只呈现部分的解析结果给用户看。

|  |  |
| --- | --- |
| **系统** | 按以下步骤回答用户问题。<br><br>第 1 步 - 首先独立解决问题。不要依赖学生的答案，因为可能有误。将此步骤的所有内容用三重引号 (""") 包围。<br><br>第 2 步 - 将你的解答与学生的答案比较，判断学生的答案是否正确。将此步骤的所有内容用三重引号 (""") 包围。<br><br>第 3 步 - 如果学生答案有误，想出一个不直接透露答案的提示。将此步骤的所有内容用三重引号 (""") 包围。<br><br>第 4 步 - 如果学生答案有误，给出第 3 步的提示（不用三重引号）。用“提示：”替代“第 4 步 - ...”。 |
| **用户** | 问题陈述：<插入问题陈述><br><br>学生解答：<插入学生解答> |

[在 Playground 中查看](https://platform.openai.com/playground/p/default-inner-monologue)

另一种方式是通过一系列的查询来实现，除了最后一个外，所有查询的结果都不展示给用户。

首先，我们可以让模型独立解决这个问题。因为这个初始步骤不需要学生的答案，所以可以省略。这样可以确保模型的答案不会受到学生答案的影响。

|  |  |
| --- | --- |
| **用户** | <插入问题陈述> |

[在 Playground 中查看](https://platform.openai.com/playground/p/default-query-sequence-1)

然后，模型将利用所有信息来判断学生的答案是否正确。

|  |  |
| --- | --- |
| **系统** | 比较并评估你的解答与学生的解答，确定学生的解答是否正确。|
| **用户** | 问题陈述："""<插入问题陈述>"""<br><br>你的解答："""<插入模型生成的解答>"""<br><br>学生的解答："""<插入学生的解答>"""|

[在 Playground 中查看](https://platform.openai.com/playground/p/default-query-sequence-2)

最后，让模型根据自己的分析以有帮助的家教身份给出回复。

|  |  |
| --- | --- |
| **系统** | 作为一个数学家教，如果学生有误，给出一个提示，但不透露答案。如果学生答案正确，就给予鼓励性的评论。 |
| **用户** | 问题陈述：""<插入问题陈述>""" <br><br>你的解答："""<插入模型生成的解答>"""<br><br>学生的解答："""<插入学生的解答>"""<br><br>分析："""<插入模型从前一步生成的分析>""" |

[在 Playground 中查看](https://platform.openai.com/playground/p/default-query-sequence-3)

## 技巧：询问模型是否有遗漏

比如我们在用模型列出与特定问题相关的摘录时，每列出一段后，模型需要决定是继续写下一个还是停止。如果原文很长，模型可能会过早结束，错过一些相关摘录。此时，通过后续查询来寻找之前遗漏的摘录，通常可以获得更好的效果。

|  |  |
| --- | --- |
| **系统** | 你将收到一个文档，其内容由三个引号界定。你的任务是选择与这个问题相关的部分：“在人工智能的发展历史中，发生了哪些重大的范式转变？”请确保你选取的摘录能够完整地提供足够的背景信息，以便理解它们的含义 — 换言之，不要选择那些缺乏重要背景信息的片段。请按照以下 JSON 格式输出结果：`[{"excerpt": "..."}, ... {"excerpt": "..."}]` |
| **用户** | """<在此处插入文档>""" |
| **助手** | [{"excerpt": "模型在此处写下一个摘录"},<br>...<br>{"excerpt": "模型在此处写下另一个摘录"}] |
| **用户** | 还有其他相关的摘录吗？请注意不要重复之前的摘录。同时确保所选摘录包含充分的背景信息，使得它们易于理解 — 也就是说，避免选择那些缺少关键背景的片段。 |

[在 Playground 中打开](https://platform.openai.com/playground/p/default-2nd-pass)
